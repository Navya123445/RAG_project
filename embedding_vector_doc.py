from langchain_openai import OpenAIEmbeddings
from langchain_weaviate import WeaviateVectorStore
import weaviate
import os
from dotenv import load_dotenv
import time
import json

load_dotenv()


def embedding_and_vector(chunks):    
    """
    Color-aware embedding and vector storage with support for:
    - Color metadata preservation and tracking
    - Annotation metadata preservation
    - JSON data cleaning for Weaviate compatibility  
    - Intelligent batch processing
    - Enhanced error handling and monitoring
    """
    model_name = os.getenv("OPENAI_MODEL", "text-embedding-3-large")
    print(f"ğŸ”„ Creating vector embeddings... using model - {model_name}")
    embeddings = OpenAIEmbeddings(model="text-embedding-3-large")
    
    weaviate_url = os.getenv("WEAVIATE_URL", "http://localhost:8081")
    weaviate_api_key = os.getenv("WEAVIATE_API_KEY")
    index_name = os.getenv("WEAVIATE_INDEX_NAME", "LegalDocuments")
    
    print(f"ğŸ”Œ Connecting to Weaviate at {weaviate_url}...")
    
    # Fixed: Proper port configuration with gRPC skip
    if weaviate_api_key:
        client = weaviate.connect_to_local(
            host="localhost", 
            port=8081,  # â† FIXED: Correct REST port
            grpc_port=50052,  # â† FIXED: Match docker-compose
            skip_init_checks=True,  # â† FIXED: Skip gRPC health check
            headers={"X-OpenAI-Api-Key": os.getenv("OPENAI_API_KEY")}
        )
    else:
        client = weaviate.connect_to_local(
            host="localhost", 
            port=8081,  # â† FIXED: Correct REST port
            grpc_port=50052,  # â† FIXED: Match docker-compose
            skip_init_checks=True  # â† FIXED: Skip gRPC health check
        )
    
    print(f"ğŸ“Š Processing {len(chunks)} color-aware chunks...")
    
    # Enhanced statistics tracking (includes color metadata)
    stats = {
        "total": 0,
        "with_annotations": 0,
        "with_financial": 0,
        "high_quality": 0,
        # ğŸ¨ Color-specific stats
        "with_color_entities": 0,
        "with_color_amounts": 0,
        "with_color_parties": 0,
        "with_color_dates": 0,
        "with_highlights": 0,
        "total_color_entities": 0
    }
    
    # Clean and process metadata for Weaviate
    processed_chunks = []
    
    for chunk in chunks:
        cleaned_metadata = {}
        
        for key, value in chunk.metadata.items():
            # Handle complex nested structures
            if key in ["structured_data", "annotations", "annotation_summary", 
                       "color_entities", "color_categories", "chunk_color_entities", 
                       "chunk_color_categories"]:
                # Store as JSON string
                if isinstance(value, str):
                    cleaned_metadata[key] = value
                else:
                    cleaned_metadata[key] = json.dumps(value) if value else ""
            
            # Handle basic types
            elif isinstance(value, (str, int, float, bool)):
                cleaned_metadata[key] = value
            elif value is None:
                cleaned_metadata[key] = ""
            else:
                # Convert complex types to strings
                cleaned_metadata[key] = str(value)
        
        chunk.metadata = cleaned_metadata
        processed_chunks.append(chunk)
        
        # Track statistics (including color metadata)
        stats["total"] += 1
        
        # Annotation stats
        if chunk.metadata.get("has_annotations", False):
            stats["with_annotations"] += 1
        if chunk.metadata.get("contains_financial_info", False):
            stats["with_financial"] += 1
        if chunk.metadata.get("high_quality_chunk", False):
            stats["high_quality"] += 1
        
        # ğŸ¨ Color metadata stats
        if chunk.metadata.get("color_entity_count", 0) > 0:
            stats["with_color_entities"] += 1
            stats["total_color_entities"] += chunk.metadata.get("color_entity_count", 0)
        
        if chunk.metadata.get("has_color_amounts", False):
            stats["with_color_amounts"] += 1
        
        if chunk.metadata.get("has_color_parties", False):
            stats["with_color_parties"] += 1
        
        if chunk.metadata.get("has_color_dates", False):
            stats["with_color_dates"] += 1
        
        if chunk.metadata.get("has_highlights", False):
            stats["with_highlights"] += 1
    
    # Batch processing configuration
    batch_size = 25
    total_batches = (len(processed_chunks) + batch_size - 1) // batch_size
    
    try:
        # Create vectorstore
        vectorstore = WeaviateVectorStore(
            client=client,
            index_name=index_name,
            text_key="text",
            embedding=embeddings
        )
        
        # Enhanced statistics reporting
        print(f"\nğŸ“ˆ ENHANCED STATISTICS:")
        print(f"   ğŸ“„ Total chunks: {stats['total']}")
        print(f"   ğŸ·ï¸  With annotations: {stats['with_annotations']}")
        print(f"   ğŸ’° With financial info: {stats['with_financial']}")
        print(f"   â­ High quality: {stats['high_quality']}")
        
        # ğŸ¨ Color-specific statistics
        print(f"\nğŸ¨ COLOR METADATA STATISTICS:")
        print(f"   ğŸŒˆ With color entities: {stats['with_color_entities']}")
        print(f"   ğŸ’µ With color-coded amounts: {stats['with_color_amounts']}")
        print(f"   ğŸ‘¥ With color-coded parties: {stats['with_color_parties']}")
        print(f"   ğŸ“… With color-coded dates: {stats['with_color_dates']}")
        print(f"   âœ¨ With highlights: {stats['with_highlights']}")
        print(f"   ğŸ“Š Total color entities: {stats['total_color_entities']}")
        if stats['with_color_entities'] > 0:
            avg_entities = stats['total_color_entities'] / stats['with_color_entities']
            print(f"   ğŸ“ˆ Avg entities per chunk: {avg_entities:.1f}")
        
        print(f"\nğŸ”¢ Processing in {total_batches} batches of {batch_size}")
        
        # Process chunks in batches with enhanced monitoring
        successful_batches = 0
        failed_batches = 0
        
        for i in range(0, len(processed_chunks), batch_size):
            batch_chunks = processed_chunks[i:i + batch_size]
            batch_num = (i // batch_size) + 1
            
            # Batch-level statistics
            batch_annotations = sum(1 for c in batch_chunks if c.metadata.get("has_annotations", False))
            batch_financial = sum(1 for c in batch_chunks if c.metadata.get("contains_financial_info", False))
            batch_color_amounts = sum(1 for c in batch_chunks if c.metadata.get("has_color_amounts", False))
            batch_color_entities = sum(c.metadata.get("color_entity_count", 0) for c in batch_chunks)
            
            print(f"   ğŸ“¦ Batch {batch_num}/{total_batches} "
                  f"({len(batch_chunks)} chunks, "
                  f"{batch_annotations} ann, "
                  f"{batch_financial} fin, "
                  f"ğŸ¨ {batch_color_amounts} $, "
                  f"{batch_color_entities} entities)...")
            
            try:
                vectorstore.add_documents(batch_chunks)
                print(f"   âœ… Batch {batch_num} completed")
                successful_batches += 1
                
            except Exception as e:
                print(f"   âŒ Batch {batch_num} failed: {e}")
                failed_batches += 1
                
                # Attempt individual chunk processing
                print(f"   ğŸ”„ Recovering batch {batch_num}...")
                individual_successes = 0
                for j, chunk in enumerate(batch_chunks):
                    try:
                        vectorstore.add_documents([chunk])
                        individual_successes += 1
                    except Exception as chunk_error:
                        print(f"     âŒ Chunk {j+1} failed: {chunk_error}")
                
                if individual_successes > 0:
                    print(f"   âš¡ Recovered {individual_successes}/{len(batch_chunks)} chunks")
            
            # API rate limiting
            if batch_num < total_batches:
                time.sleep(0.5)
        
        # Comprehensive summary
        print(f"\nğŸ¯ EMBEDDING COMPLETION SUMMARY:")
        print(f"   âœ… Successful batches: {successful_batches}/{total_batches}")
        if failed_batches > 0:
            print(f"   âŒ Failed batches: {failed_batches}")
            print(f"   ğŸ“Š Success rate: {(successful_batches/total_batches)*100:.1f}%")
        else:
            print(f"   ğŸŒŸ Perfect success: 100%")
        
        print(f"\nğŸ¨ COLOR-AWARE FEATURES ENABLED:")
        print(f"   âœ“ Color-coded amount filtering (has_color_amounts)")
        print(f"   âœ“ Color-coded party filtering (has_color_parties)")
        print(f"   âœ“ Color-coded date filtering (has_color_dates)")
        print(f"   âœ“ Highlight annotation tracking")
        print(f"   âœ“ Entity count-based ranking")
        
        print(f"\nğŸ·ï¸  ANNOTATION FEATURES ENABLED:")
        print(f"   âœ“ High-quality chunk filtering")
        print(f"   âœ“ Financial content prioritization") 
        print(f"   âœ“ Entity confidence scoring")
        print(f"   âœ“ Cross-document relationship mapping")
        
        print(f"\nâœ… Enhanced embeddings stored in Weaviate: {index_name}")
        
    except Exception as e:
        print(f"âŒ Critical error creating vector store: {e}")
        client.close()
        raise
    
    return vectorstore
    